{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Store Number</th>\n",
       "      <th>Customer Segment</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Visits</th>\n",
       "      <th>Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>PAMELA</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>2316 E 5TH AVE</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>CO</td>\n",
       "      <td>80206</td>\n",
       "      <td>1</td>\n",
       "      <td>206.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>MELISSA</td>\n",
       "      <td>RUFF</td>\n",
       "      <td>2753 S MILWAUKEE ST</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>CO</td>\n",
       "      <td>80210</td>\n",
       "      <td>1</td>\n",
       "      <td>228.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>104</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>CONSTANTI</td>\n",
       "      <td>VLASSIS</td>\n",
       "      <td>16911 E HARVARD AVE</td>\n",
       "      <td>AURORA</td>\n",
       "      <td>CO</td>\n",
       "      <td>80013</td>\n",
       "      <td>1</td>\n",
       "      <td>432.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002</td>\n",
       "      <td>104</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>AMY</td>\n",
       "      <td>LOCKEMER</td>\n",
       "      <td>3721 S PITKIN CT</td>\n",
       "      <td>AURORA</td>\n",
       "      <td>CO</td>\n",
       "      <td>80013</td>\n",
       "      <td>4</td>\n",
       "      <td>2101.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>101</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>DANELL</td>\n",
       "      <td>VALDEZ</td>\n",
       "      <td>2925 W COLLEGE AVE</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>CO</td>\n",
       "      <td>80219</td>\n",
       "      <td>1</td>\n",
       "      <td>1404.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>995</td>\n",
       "      <td>103</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>ELIZABETH</td>\n",
       "      <td>SAROW</td>\n",
       "      <td>10915 W 103RD CT</td>\n",
       "      <td>BROOMFIELD</td>\n",
       "      <td>CO</td>\n",
       "      <td>80021</td>\n",
       "      <td>1</td>\n",
       "      <td>72.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>996</td>\n",
       "      <td>106</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>KRISTA</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>1696 TAFT ST</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>CO</td>\n",
       "      <td>80215</td>\n",
       "      <td>1</td>\n",
       "      <td>36.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>997</td>\n",
       "      <td>100</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>ILA</td>\n",
       "      <td>CRAMER</td>\n",
       "      <td>2984 E AMHERST AVE</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>CO</td>\n",
       "      <td>80210</td>\n",
       "      <td>1</td>\n",
       "      <td>63.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>998</td>\n",
       "      <td>108</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>CHARLOTTE</td>\n",
       "      <td>SHAIN</td>\n",
       "      <td>14288 W 69TH PL</td>\n",
       "      <td>ARVADA</td>\n",
       "      <td>CO</td>\n",
       "      <td>80004</td>\n",
       "      <td>1</td>\n",
       "      <td>595.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>999</td>\n",
       "      <td>101</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>JOANNE</td>\n",
       "      <td>WOODY</td>\n",
       "      <td>9223 W VIRGINIA DR</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>CO</td>\n",
       "      <td>80226</td>\n",
       "      <td>1</td>\n",
       "      <td>127.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2669 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer_ID  Store Number Customer Segment First Name Last Name  \\\n",
       "0              10           100      Home Office     PAMELA    WRIGHT   \n",
       "1             100           100         Consumer    MELISSA      RUFF   \n",
       "2            1000           104   Small Business  CONSTANTI   VLASSIS   \n",
       "3            1002           104      Home Office        AMY  LOCKEMER   \n",
       "4            1003           101      Home Office     DANELL    VALDEZ   \n",
       "...           ...           ...              ...        ...       ...   \n",
       "2664          995           103   Small Business  ELIZABETH     SAROW   \n",
       "2665          996           106   Small Business     KRISTA   JOHNSON   \n",
       "2666          997           100   Small Business        ILA    CRAMER   \n",
       "2667          998           108   Small Business  CHARLOTTE     SHAIN   \n",
       "2668          999           101   Small Business     JOANNE     WOODY   \n",
       "\n",
       "                  Address        City State    Zip  Visits    Spend  \n",
       "0          2316 E 5TH AVE      DENVER    CO  80206       1   206.95  \n",
       "1     2753 S MILWAUKEE ST      DENVER    CO  80210       1   228.27  \n",
       "2     16911 E HARVARD AVE      AURORA    CO  80013       1   432.44  \n",
       "3        3721 S PITKIN CT      AURORA    CO  80013       4  2101.11  \n",
       "4      2925 W COLLEGE AVE      DENVER    CO  80219       1  1404.09  \n",
       "...                   ...         ...   ...    ...     ...      ...  \n",
       "2664     10915 W 103RD CT  BROOMFIELD    CO  80021       1    72.83  \n",
       "2665         1696 TAFT ST      DENVER    CO  80215       1    36.16  \n",
       "2666   2984 E AMHERST AVE      DENVER    CO  80210       1    63.66  \n",
       "2667      14288 W 69TH PL      ARVADA    CO  80004       1   595.99  \n",
       "2668   9223 W VIRGINIA DR      DENVER    CO  80226       1   127.22  \n",
       "\n",
       "[2669 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/cust-wtransactions.xls')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2669 entries, 0 to 2668\n",
      "Data columns (total 11 columns):\n",
      "Customer_ID         2669 non-null int64\n",
      "Store_Number        2669 non-null int64\n",
      "Customer_Segment    2669 non-null object\n",
      "First_Name          2669 non-null object\n",
      "Last_Name           2669 non-null object\n",
      "Address             2669 non-null object\n",
      "City                2669 non-null object\n",
      "State               2669 non-null object\n",
      "Zip                 2669 non-null int64\n",
      "Visits              2669 non-null int64\n",
      "Spend               2669 non-null float64\n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 229.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Stores have over 300 customers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['Store_Number'].value_counts()>300).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    357\n",
       "105    351\n",
       "106    318\n",
       "101    313\n",
       "104    306\n",
       "Name: Store_Number, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# who are those stores?\n",
    "data.Store_Number.value_counts()[data['Store_Number'].value_counts()>300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read xml or html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.read_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Project 2.1 - Preparing School Data\n",
    "As always, we start with the Problem Solving Framework\n",
    "\n",
    "## Business Understanding\n",
    "A school district wants to predict the per pupil costs of a school based on some high level summary data about the school. This way they’ll have a good estimation of how well a school is managing its costs relative to what the model would predict. You’ve been asked to to prepare the data for modelling.\n",
    "\n",
    "Data Understanding\n",
    "You’ve been given four CSV files that contain data for two different school districts. You can find these files at the bottom of the page.\n",
    "\n",
    "DistrictA_Attendance - This file contains average daily attendance, percent attendance, and pupil-teacher ratio data for the 25 schools in district A.\n",
    "DistrictA_Finance - This file contains average monthly teacher salary and per pupil cost data for the 25 schools in district A.\n",
    "DistrictB_Attendance - This file contains average daily attendance, percent attendance, and pupil-teacher ratio data for the 21 schools in district B.\n",
    "DistrictB_Finance - This file contains average monthly teacher salary and per pupil cost data for the 21 schools in district B.\n",
    "Data Preparation\n",
    "Step 1: Combine the data\n",
    "First you’ll need to combine the data from the various files into one sheet, with one row per school. To do this, you’ll use the skills you learned in the Formatting Data and Blending Data lessons.\n",
    "\n",
    "Step 2: Clean the Data\n",
    "Next you’ll clean the data, which includes addressing duplicate data, missing data, and any other data issues. To do this, you’ll use the skills you learned in the Data Issues lesson.\n",
    "\n",
    "Step 3: Identify and Deal with Outliers\n",
    "Lastly, you’ll look for outliers and determine the best way to address them. To do this, you’ll use the skills you learned in the Data Issues lesson.\n",
    "\n",
    "Self-Assessment\n",
    "Do your best to complete the practice project on your own. Once you are done, or get stuck, take a look at the solution. We’ve provided the solution dataset, Alteryx workflow, as well as a walk through of how to complete the project. There's not necessarily one perfectly right answer.\n",
    "\n",
    "\n",
    "Supporting Materials\n",
    "DistrictA Attendance\n",
    "DistrictA Finance\n",
    "DistrictB Attendance\n",
    "DistrictB Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources for Self Assessment\n",
    "You have three resources to assess how you did on the practice project and how ready you are for a project you will submit.\n",
    "\n",
    "Solution Dataset\n",
    "At the bottom of the page you will see the Cleaned School Data file. There are a few judgement calls to make on regarding outliers and missing data, so your solution may look a little different. Take a look and compare to your cleaned dataset.\n",
    "\n",
    "Alteryx Solution Workflow\n",
    "At the bottom of the page you will see an Alteryx workflow that provides a sample solution. You're solution may not look exactly the same. Take a look at the workflow to see how I approached it. You can also see a snapshot of the workflow below. Don't worry, it's not as complicated as it looks.\n",
    "\n",
    "Detailed Walkthrough\n",
    "See the next for a more detailed walk through on the process. You learn how to learn the Score tool, which makes applying the model results much easier.\n",
    "\n",
    "\n",
    "Supporting Materials\n",
    "Practice P2 Solution Workflow\n",
    "Cleaned School Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "To begin, let’s take a look at the data. The data is in four different csv files, which we’ll have to combine in order to do the analysis.\n",
    "\n",
    "To import, we’ll bring in four input tools, each one bringing in one of the files. There are two files for each district: an attendance file and a finance file.\n",
    "\n",
    "Starting with District A’s attendance file, we one record for each school, and there are three numeric fields, average attendance, percent attendance, and pupil teacher ratio.\n",
    "\n",
    "District A’s finance tab is structured differently. It has multiple rows for each school because the numeric fields are stacked on top of each other. So this data will have to be transformed before we can merge it with the attendance data.\n",
    "\n",
    "District B’s two datasets are structured similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting and Blending Data\n",
    "To build the dataset, we’ll have to merge each of these datasets into one.\n",
    "\n",
    "First, we’ll have to transform the finance datasets\n",
    "Then we’ll merge the finance and attendance datasets for each district\n",
    "And lastly we’ll combine the data for the two districts together.\n",
    "Transforming with Crosstab\n",
    "To transform the finance datasets, connect a Crosstab tool it to each of the finance input tools.\n",
    "\n",
    "In the configuration window, select School as the group by value, metric as the column headers, and value for the Values for New Columns. This will format the data in the same way the attendance data is formatted.\n",
    "\n",
    "Join\n",
    "Next, bring in a join tool and connect both datasets.\n",
    "\n",
    "In the configuration window, select the school variable in each of the datasets to join on. Then select the variables you want to keep. You can drop one of the school variables, but you should keep the 5 numeric variables. You’ll want to do the same for the other district.\n",
    "\n",
    "Union\n",
    "Next, bring in a union tool, which will stack the data on top of eachother. Since the datasets have the same variables, you don’t have to set any configurations.\n",
    "\n",
    "This is good time to rename variables, since the variable names are pretty long. To do this, bring in a select tool. I’ve changed the names to ATT, PATT, PTR, SAL, and PPC. Let’s attached a browse tool and take a look at what we’ve got. Now the data is looks like it's in good format for analysis and modeling.\n",
    "\n",
    "Many analysts at this point will output the dataset to make future data cleaning go a bit faster. In this case, it's not as important because we don't have a lot of data. But imagine doing this on datasets with millions of records; run time can take a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "Now let’s check for data issues. Specifically, let’s look for duplicates and missing data first.\n",
    "\n",
    "Visualizing with the Field Summary Tool\n",
    "Visualizing the data is a good way of doing this. The field summary report gives a few reports that are helpful. Looking at histograms of each variable is a good way to do this.\n",
    "\n",
    "\n",
    "Duplicate Data\n",
    "First, we see a potential duplicate because there’s one school with two records. Let’s take a look at the observations to confirm. All the data is the same for these two records, so it appears to be a duplicate. So let’s delete one of the observations.\n",
    "\n",
    "There are several ways to do this. An easy way is to use the select records tool. The record we want to delete is number 39, so in the configuration window of the select records tool, we can select 1-38 and everything 40 and after.\n",
    "\n",
    "The record we want to delete is number 39, so in the configuration window of the select records tool, we can select 1-38 and everything 40 and after.\n",
    "\n",
    "Missing Data\n",
    "You can see on the field summary report we are missing a few observations for the two attendance variables (the red underneath the histogram indicates this). We can either delete or impute. Since there are only a few, let’s delete the records, but we’ll make note of it, since we may come back to run the model with the data imputed, or if we end up not using those variables in the model.\n",
    "\n",
    "An easy way to remove missing data is to use a filter tool.\n",
    "\n",
    "In the configuration window, you can select the ATT variable, and filter out records that are NULL. To do this, you want to keep all records that are not NULL, so you can use the drop downs to select ATT Is Not Null, or type in the formula !IsNull(ATT).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying and dealing with outliers\n",
    "We are working on providing more detail to this sections. In the meantime, here's an overview.\n",
    "\n",
    "To check for outliers, let’s start with some scatterplots to visualize the relationship between each predictor variable and the target variable. Since there are four predictor variables, let’s drag in four scatterplot tools, and connect them to the cleaned dataset. Then we configure each one with a different predictor variable, attached browse tools, and run the workflow.\n",
    "\n",
    "Let’s start with attendance. The box and whisker plots on either axis use the interquartile range to determine whether a point is an outlier. You can see hear there are two dramatic outliers for attendance, so let’s address those first, then come back to the others.. If you need a quick refresher on what to do with outliers, take a look at the notes below the video.\n",
    "\n",
    "For these outliers, it looks like the data may not be record properly. Let’s look at the observations by attaching a sort tool and browse tool to the dataset. You can see that almost every observation has a decimal, and these two observations seem to be about 10X the average, so it’s highly likely that the data is an error and we should divide by 10. Normally we would validate with the source, but for now we’ll just make the assumption. I’ll use a formula tool to filter out these records, and create another scatter plot.\n",
    "\n",
    "ATTENDANCE: There still is one more outlier. For this one, it seems like the data is probably right, and it’s just a larger school. My concern with keeping this observation is that it may skew the data, creating or masking a relationship with PPC. If I knew that none of the schools I was predicting for were going to be that size, I’d delete it. Otherwise, I’d keep it in. Let’s plan on building a model with and without this variable.\n",
    "\n",
    "PERCENT ATTENDANCE: Now let’s look at percent attendance. There doesn’t appear to be outliers. Great.\n",
    "\n",
    "PUPIL TEACHER RATIO: For Pupil Teacher Ratio, there are 2 outliers, which are the also outliers for PPC. This makes sense since we’d expect the relationship to behave this way. Based on the fitted line, the outliers are in line with the relationship, so we’d leave them in.\n",
    "\n",
    "TEACHER SALARIES: Two records are outliers, with very low salaries. Just like for PTR, these seem to be in line with the trend, and not dramatically different, so it’s probably best to keep them in.\n",
    "\n",
    "NOTE: In this example, because of the small size of the dataset, we could look at each outlier and make decisions. For larger data sets, you’d likely have to make more systematic decisions, such as removing all outliers, or removing the top 1 or 2 percent of observations for each variable.\n",
    "\n",
    "Outlier Summary\n",
    "So, we kept 4 of the 5 outliers, and we’ll run the model with and without the fifth one. So now we are ready for modeling. Nice work.\n",
    "\n",
    "How do deal with outliers\n",
    "As a reminder, let’s quickly review how to handle an outlier. There are three main methods:\n",
    "\n",
    "Delete: When data is erroneous or when the outlier hurts the model's’ ability to make prediction (perhaps the value is very unlikely to appear again so keeping it in the model will skew all other predictions).\n",
    "Impute: Also for when data is erroneous, we could use the average or median value in its place.\n",
    "Leave it: If the data is good data, it may be best to leave the data in and try with and without to see the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "This project is the first part of a two-part series. In the first part, you will blend and format data and deal with outliers.\n",
    "\n",
    "For the second part, you will use your cleaned up dataset to create another linear regression model. The difference this time is that you will have to choose which variable(s) are the most important for the model using new techniques learned in the More on Predictor Variables lesson.\n",
    "\n",
    "Scenario\n",
    "Pawdacity is a leading pet store chain in Wyoming with 13 stores throughout the state. This year, Pawdacity would like to expand and open a 14th store. Your manager has asked you to perform an analysis to recommend the city for Pawdacity’s newest store, based on predicted yearly sales.\n",
    "\n",
    "How Do I Complete this Project?\n",
    "This project uses skills learned throughout the \"Data Preparation” lessons. To complete this project:\n",
    "\n",
    "Go through the course.\n",
    "Apply the skills learned in the course to solve the business problem given in the project details.\n",
    "Use our guidelines and rubric to help build your project.\n",
    "When you're ready, submit it to us for review using the submission template found in the supporting materials section.\n",
    "Skills Required\n",
    "In order to complete this project, you must be able to:\n",
    "\n",
    "Understand different data types\n",
    "Deal with a variety of data issues\n",
    "Format data appropriately\n",
    "Blend data together using joins and unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
